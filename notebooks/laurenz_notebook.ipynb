{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic setup for fetching data from the facebook api\n",
    "\n",
    "### Remember to add an active access token below and adjust the parameters and fields if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be specified to be able to use methods of package\n",
    "import sys\n",
    "sys.path.append('../src') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from political_ads.api_request import API_request\n",
    "from political_ads.preprocessor import Preprocessor\n",
    "\n",
    "# Generates a dataset (in the data directory)\n",
    "# requestor = API_request()\n",
    "# requestor.generate_dataset(500, \"Joe Biden\", \"EAAD3So8oorMBAIgWyz9birkjFZCRkyKZADF6qfnmkZC41UPKMzeoSWPXLXxNTBiFP9td55s5TZCOKfAoheAmRih0U7TjaCCDsDQwZAZCBPH2pGQtx6y9e9Keouk8JosvkuLPxs451MY3QGrzZAgiZAVKFJZBxZCIFxHIKHVJmn8uwnGsJaMKh1mQIknChEeYf16tYyZCZBehAo4VToZCuqW0P5KL2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns text file as dataframe with transformations\n",
    "preprocess = Preprocessor()\n",
    "data = preprocess.file_to_df(\"..\\\\data\\\\generated_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualization attempts\n",
    "https://pandas.pydata.org/pandas-docs/dev/getting_started/intro_tutorials/09_timeseries.html\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting spending over time and impressions over time \n",
    "fig, axes = plt.subplots(2,1,figsize=(8,4))\n",
    "data.plot(x=\"ad_creation_time\", y=\"impressions\", ax=axes[0])\n",
    "data.plot(x=\"ad_creation_time\", y=\"spend\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot range of impressions\n",
    "plt.fill_between(x=data[\"ad_creation_time\"], y1=data[\"impressions_lo\"], y2=data[\"impressions_hi\"], alpha=1, color=\"green\")\n",
    "plt.plot(data[\"ad_creation_time\"], data[\"impressions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Amount spend by facebook page\n",
    "'''\n",
    "by_page = data.groupby(\"page_name\").agg(\n",
    "    # Aggregate no of ads\n",
    "    no_ads = ('id', 'count'),\n",
    "    # Aggregate sum of spend & total impressions generated\n",
    "    spend_lo = ('spend_lo', 'sum'),\n",
    "    spend_hi = ('spend_hi', 'sum'),\n",
    "    impressions_lo = ('impressions_lo', 'sum'),\n",
    "    impressions_hi = ('impressions_hi', 'sum'),\n",
    "    # Average number of impressions & spend per ad\n",
    "    avg_impressions = ('impressions', 'mean'),\n",
    "    avg_spend = ('spend', 'mean')\n",
    "\n",
    ").reset_index()\n",
    "\n",
    "by_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display range of spend\n",
    "\n",
    "# Maybe normalize it\n",
    "plt.fill_between(x=by_page[\"page_name\"], y1=by_page[\"spend_lo\"], y2=by_page[\"spend_hi\"], alpha=1, color=\"green\")\n",
    "plt.plot(by_page[\"page_name\"], by_page[\"spend\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Congress member filtering\n",
    "'''\n",
    "# Get page-ids:\n",
    "# https://commentpicker.com/find-facebook-id.php\n",
    "\n",
    "\n",
    "congress_members = pd.DataFrame(pd.read_csv(\"..\\\\src\\\\data_sets\\\\legislators-current.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_members[\"facebook\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_members[\"facebook\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraper experiement\n",
    "# https://github.com/kevinzg/facebook-scraper\n",
    "\n",
    "from facebook_scraper import get_page_info\n",
    "\n",
    "page = get_page_info(account=\"SenatorBobCasey\")\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "members_fbNames_test = [] # list of tuples\n",
    "\n",
    "for value in congress_members[\"facebook\"].items():\n",
    "    if not pd.isnull(value[1]):\n",
    "        page = get_page_info(account=value[1])\n",
    "        print(page)\n",
    "        if \"name\" and \"identifier\" in page:\n",
    "            members_fbNames_test.append((value[1], page[\"name\"], page[\"identifier\"]))\n",
    "            print(page[\"name\"] + \" id:\" + str(page[\"identifier\"]))\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_names = pd.DataFrame(members_fbNames_test, columns=[\"facebook\", \"page_name\", \"identifier\"])\n",
    "# Save data as csv\n",
    "members_names.to_csv(\"..\\\\src\\\\data_sets\\\\legislators_page_ids.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_names_cp = members_names.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_members_fb = congress_members[[\"first_name\", \"last_name\", \"full_name\", \"type\", \"state\", \"district\", \"party\", \"facebook\"]]\n",
    "\n",
    "merged = congress_members_fb.merge(right=members_names, on=\"facebook\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"identifier\"] = merged[\"identifier\"].fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"identifier\"] = merged[\"identifier\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"..\\\\src\\\\data_sets\\\\legislators_fb_info.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_csv(\"..\\\\src\\\\data_sets\\\\legislators_fb_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress[\"full_name\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv(\"..\\\\data\\\\FacebookAdLibraryReport_2021-10-15_US_lifelong_advertisers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(report[report[\"Page Name\"].str.contains(\"Kpoadjioasdjqwodjas\", na=False)]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_id(data: pd.DataFrame, name: str):\n",
    "    match = data[data[\"Page Name\"].str.contains(name, na=False)]\n",
    "    if len(match) != 0:\n",
    "        return match.iloc[0][0]\n",
    "    else:\n",
    "        return \"no match\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page_id(report, \"Bernie Sanders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress[\"page_id\"] = congress.apply(lambda x: get_page_id(report,x[\"full_name\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress[congress[\"page_id\"] == \"no match\"].count()\n",
    "\n",
    "congress.to_csv(\"..\\\\src\\\\data_sets\\\\legislators_fb_info.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "congress = pd.read_csv(\"..\\\\src\\\\data_sets\\\\legislators_fb_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be specified to be able to use methods of package\n",
    "import sys\n",
    "sys.path.append('../src') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from political_ads.api_request import API_request\n",
    "from political_ads.preprocessor import Preprocessor\n",
    "\n",
    "# Generates a dataset (in the data directory)\n",
    "test_ids = [6266829799, 9351652533, 2220944231249057, 101501768597429, 876319055750124, 512954815727434]\n",
    "requestor = API_request()\n",
    "requestor.generate_dataset_by_pageId(500, test_ids, \"EAAD3So8oorMBAPcQZCsrdT0p2lsvUuyLQozbZCnvnJnmZCeswClj2dXakZCMkPZB8B0m3qf2Ynojj31VzBZBZBd31KuUhNr1ukt9tilFGyFNhbZB4ak36zvz8LOH165dAXvmZCqbtjjvgZAXb4PbJ0ICuVpPrb9y9MqZBvk7EswvSvBCS4LXTZBEFowcoNYXZBZBuf7Ll09kPzLBsAOvktd3EepEMqsMOryyE2ZBvcudXeXB7ZCoFgeLSlDoHbNpsikZASAFriewZD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read json file\n",
    "with open('..\\\\data\\\\dataset_by_pageId.txt') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# load existing file\n",
    "# file =  open(\"..\\\\data\\\\dataset_by_pageId.txt\")\n",
    "# json_ = json.loads(file)\n",
    "\n",
    "json_data_1 = json_data \n",
    "\n",
    "json_data.extend(json_data_1)\n",
    "# json_.extend(json_data) # add string to file\n",
    "jsonFile = open(\"..\\\\data\\\\dataset_by_pageId.txt\", \"w\") # filepath and name specified here!\n",
    "final_str = json.dumps(json_data) \n",
    "jsonFile.write(final_str)\n",
    "jsonFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # load existing file\n",
    "with open('..\\\\data\\\\dataset_by_pageId.txt') as f:\n",
    "    existing_file = json.load(f)\n",
    "existing_file.extend(\"bablabl\") # add string to file\n",
    "jsonFile = open(\"..\\\\data\\\\dataset_by_pageId_appended.txt\", \"w\") # filepath and name specified here!\n",
    "final_file_str = json.dumps(existing_file)\n",
    "jsonFile.write(final_file_str)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be specified to be able to use methods of package\n",
    "import sys\n",
    "sys.path.append('../src') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from political_ads.api_request import API_request\n",
    "from political_ads.preprocessor import Preprocessor\n",
    "\n",
    "preprocess = Preprocessor()\n",
    "\n",
    "data = preprocess.file_to_df(\"..\\\\data\\\\dataset_by_pageId.txt\")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_csv(\"..\\\\src\\\\data_sets\\\\legislators_fb_info.csv\")\n",
    "congress.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# trying to make continuous loop to fetch all data\n",
    "import sys\n",
    "sys.path.append('../src') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from political_ads.api_request import API_request\n",
    "from political_ads.preprocessor import Preprocessor\n",
    "\n",
    "requestor = API_request()\n",
    "\n",
    "count = 0\n",
    "while count < 20:\n",
    "    query = []\n",
    "    for i in range(10):\n",
    "        if count < len(congress):\n",
    "            query.append(congress.loc[count][\"page_id\"])\n",
    "            count +=1\n",
    "    # clean query / remove \"no match\"\n",
    "    clean_query = []\n",
    "    for i in range(len(query)):\n",
    "        if query[i] != \"no match\":\n",
    "            clean_query.append(query[i])\n",
    "    print(clean_query)\n",
    "    \n",
    "    requestor.append_dataset_by_pageId(500, clean_query, \"EAAD3So8oorMBAL9qzc2ZBrrDaNqfJkAbHy6KPqZCqNmhOAvAzEIauoJOqruWt4f9oIiw4YsgX7Qs5l4y291PQBery6ZBBDOnKvxV4lGx6ZCOZChxMdCOvz9GNGstwdgtGUakHzmNYbldZBjNZBFyMjb9ZACYVygAcFToyMkK5cfp4s9C4mvjIBD1OBkvuZBWAB4IRcZB4XXEZBiVWo2ZAJWIfNIJnocHmW5EZB9ZAIkT60Ddbwf0IlFmwUWpFNH4YGVx3uESAZD\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                Sherrod\n",
       "last_name                   Brown\n",
       "full_name           Sherrod Brown\n",
       "type                          sen\n",
       "state                          OH\n",
       "district                      NaN\n",
       "party                    Democrat\n",
       "facebook      SenatorSherrodBrown\n",
       "page_name                     NaN\n",
       "identifier                      0\n",
       "page_id                6266829799\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (Temp/ipykernel_7068/1672595199.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\laise\\AppData\\Local\\Temp/ipykernel_7068/1672595199.py\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    print(f\"Try politician {politician[\"full_name\"]}\")\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# fetch all ads by one page and concatenate them to final file\n",
    "import sys\n",
    "sys.path.append('../src') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from political_ads.api_request import API_request\n",
    "from political_ads.preprocessor import Preprocessor\n",
    "import json\n",
    "\n",
    "\n",
    "requestor = API_request()\n",
    "\n",
    "count = 0\n",
    "final_file = []\n",
    "while count < len(congress):\n",
    "    politician_name = congress.loc[count][\"full_name\"]\n",
    "    page_id = congress.loc[count][\"page_id\"]\n",
    "    print(f\"Try politician {politician_name}\")\n",
    "    if page_id != \"no match\":\n",
    "        print(f\"Page ID exists!\")\n",
    "        final_file.extend(requestor.dataset_by_pageId_asString(500, [page_id], \"EAAD3So8oorMBAL9qzc2ZBrrDaNqfJkAbHy6KPqZCqNmhOAvAzEIauoJOqruWt4f9oIiw4YsgX7Qs5l4y291PQBery6ZBBDOnKvxV4lGx6ZCOZChxMdCOvz9GNGstwdgtGUakHzmNYbldZBjNZBFyMjb9ZACYVygAcFToyMkK5cfp4s9C4mvjIBD1OBkvuZBWAB4IRcZB4XXEZBiVWo2ZAJWIfNIJnocHmW5EZB9ZAIkT60Ddbwf0IlFmwUWpFNH4YGVx3uESAZD\"))\n",
    "    count += 1\n",
    "\n",
    "jsonFile = open(\"..\\\\data\\\\dataset_by_pageId_appended.txt\", \"w\") # filepath and name specified here!\n",
    "        \n",
    "final_file_str = json.dumps(final_file)\n",
    "jsonFile.write(final_file_str)\n",
    "jsonFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # # load existing file\n",
    "        # with open('..\\\\data\\\\dataset_by_pageId_appended.txt') as f:\n",
    "        #     existing_file = json.load(f)\n",
    "# existing_file.extend(final_response) # add string to file\n",
    "import json\n",
    "\n",
    "jsonFile = open(\"..\\\\data\\\\dataset_by_pageId_appended.txt\", \"w\") # filepath and name specified here!\n",
    "        \n",
    "final_file_str = json.dumps(final_file)\n",
    "jsonFile.write(final_file_str)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be specified to be able to use methods of package\n",
    "import sys\n",
    "sys.path.append('../src') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from political_ads.api_request import API_request\n",
    "from political_ads.preprocessor import Preprocessor\n",
    "\n",
    "preprocess = Preprocessor()\n",
    "\n",
    "data = preprocess.file_to_df(\"..\\\\data\\\\dataset_by_pageId_appended.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"page_name\"]).agg(\"count\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
