{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src') \n",
    "from political_ads.preprocessor import Preprocessor\n",
    "\n",
    "preprocess = Preprocessor()\n",
    "data = preprocess.file_to_df(\"..\\\\data\\\\all_politicians_aggregated_final.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from political_ads.keyword_filter import Filter\n",
    "import pandas as pd\n",
    "\n",
    "# filter object\n",
    "filter = Filter()\n",
    "\n",
    "climate_ads = filter.get_climate_ads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small = data.sample(n=1000)\n",
    "data_mini = data.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = pd.read_csv(\"..\\\\data\\\\split_dataset\\\\no_duplicates_chunk_6_labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = labeled[labeled[\"unique_label\"] == \"environment\"]\n",
    "labeled.iloc[5294][\"ad_creative_body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the labeled chunks and add them back to the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for i in range(7):\n",
    "    print(f\"Labeling Chunk {i}\")\n",
    "    chunk = pd.read_csv(f\"..\\\\data\\\\split_dataset\\\\no_duplicates_chunk_{i}_labelled.csv\")\n",
    "    frames.append(chunk)\n",
    "    #chunk.to_csv(f\"..\\\\data\\\\split_dataset\\\\no_duplicates_chunk_{i}_labelled.csv\", index=False)\n",
    "\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"..\\\\data\\\\split_dataset\\\\merged_chunks_labelled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labeled = pd.read_csv(\"..\\\\data\\\\split_dataset\\\\merged_chunks_labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled[labeled[\"ad_creative_body\"] == \"Hope to see everyone tonight!\"].index[0]\n",
    "\n",
    "labeled.iloc[60636][\"unique_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write method that adds the label to each row of the total advertisements dataframe data\n",
    "'''\n",
    "# import progress bar\n",
    "from tqdm import tqdm\n",
    "# instantiate tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def add_label(row):\n",
    "    text = row[\"ad_creative_body\"]\n",
    "    label = labeled[labeled[\"ad_creative_body\"] == text][\"unique_label\"]\n",
    "    return label\n",
    "\n",
    "# Progress apply to data\n",
    "data[\"zero_label\"] = data.progress_apply(add_label, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Zero Shot Classification on Big Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers\n",
    "#%pip install tensorflow\n",
    "#%pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install huggingface transformers\n",
    "#pip install transformers\n",
    "# Use progress bar\n",
    "#%pip install tqdm\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# Helper function: Return the best two lables with the corresponding scores\n",
    "def assign_labels(sentence, model, tags):\n",
    "    try:\n",
    "      results = model(sentence, tags, multi_clsass=True)\n",
    "      labels = {}\n",
    "      labels[results['labels'][0]] = round(float(results['scores'][0]), 2)\n",
    "      labels[results['labels'][1]] = round(float(results['scores'][1]), 2)\n",
    "      #rs = f\"{results['labels'][0]} ({results['scores'][0]:.2f}), {results['labels'][1]} ({results['scores'][1]:.2f})\"\n",
    "      return labels\n",
    "    except:\n",
    "      return \"not_classified\"\n",
    "\n",
    "# helper to get only the first label\n",
    "def get_first_label(labels: dict):\n",
    "  try:\n",
    "    # only if value is above threshold of 85%\n",
    "    first = \"\"\n",
    "    for k, v in labels.items():\n",
    "      if v >= 0.85:\n",
    "        first = k\n",
    "        break\n",
    "      else:\n",
    "        return \"not_classified\"\n",
    "    return first\n",
    "  except:\n",
    "    return \"not_classified\"\n",
    "\n",
    "# main function that applies zero shot classification to the texts and adds labels & unique label columns\n",
    "def generate_labels(input: pd.DataFrame) -> pd.DataFrame:\n",
    "  tqdm.pandas()\n",
    "  output = input.copy()\n",
    "  classifier = pipeline(\"zero-shot-classification\")\n",
    "  # Define candidate tags\n",
    "  candidates_tags = [\"climate change\"]\n",
    "  # Apply to mini test data\n",
    "  # Use use apply with tqdm progress bar\n",
    "  output[\"labels\"] = output[\"ad_creative_body\"].progress_apply(assign_labels, model=classifier, tags=candidates_tags)\n",
    "  output[\"unique_label\"] = output[\"labels\"].apply(get_first_label)\n",
    "  return output\n",
    "\n",
    "#mini_sample_en = generate_labels(mini_sample_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall tensoflow\n",
    "# %pip install tensorflow==2.2.0\n",
    "# %pip unsinstall transformer\n",
    "# %pip install transformer==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = generate_labels(data_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which ad_creative_body texts are duplicated\n",
    "data_small.drop_duplicates(subset=\"ad_creative_body\", keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates = data.drop_duplicates(subset=\"ad_creative_body\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - df: a Dataframe, chunkSize: the chunk size\n",
    "# output - a list of DataFrame\n",
    "# purpose - splits the DataFrame into smaller chunks\n",
    "def split_dataframe(df, chunk_size = 10000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_dataframe(no_duplicates)\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    chunks[i].to_csv(f\"..\\\\data\\\\split_dataset\\\\no_duplicates_chunk_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(chunks)):\n",
    "    print(f\"Labeling Chunk {i}\")\n",
    "    chunk = pd.read_csv(f\"..\\\\data\\\\split_dataset\\\\no_duplicates_chunk_{i}.csv\")\n",
    "    chunk = generate_labels(chunk)\n",
    "    chunk.to_csv(f\"..\\\\data\\\\split_dataset\\\\no_duplicates_chunk_{i}_labelled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1471b608e2a7559dfe4acf35b90d904c5a7144cf90e81ff4e5b9fbc3e2b57374"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
